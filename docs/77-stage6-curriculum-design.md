# 77 — Stage 6 GEO 과업 실행 커리큘럼 상세 설계

**문서 목적**: Stage 6 모듈 구조, 스텝 설계, 콘텐츠 원칙을 개발자가 `seed.py`에 구현할 수 있을 정도로 상세화

**대상**: `docs/73-geo-action-plan.md`의 90일 로드맵을 학습/실행형 모듈로 변환

**버전**: 2026-02-23

---

## 1. 모듈 설계 개요 (8개 모듈, Phase-순차 구조)

### 설계 원칙 변경 (v2.0, 2026-02-23)

기존 v1.0의 **기능별 7모듈** 구조에서 `docs/73-geo-action-plan.md`의 **Phase 순차 8모듈** 구조로 전환함.

**변경 이유:**
- 사용자 요구: "팀원들이 순차 과업 수행" → Phase 1→2→3 순서 그대로 따라야 함
- 기능별 그룹핑은 여러 Phase를 한 모듈에 섞어 실행 순서가 불명확했음
- Phase 순차 구조: 모듈 1→8을 따라가면 자동으로 30→60→90일 로드맵 실행

**최종 구조**: 8개 모듈 × 4스텝 = 32스텝, 96옵션

| 모듈 | 제목 | Phase | 커버 티켓 | 스텝 |
|------|------|-------|----------|------|
| M6-1 | 킥오프 & 현황 진단 | 0 | — | 1R+1Q+2P |
| M6-2 | 기술 인프라 정비 | 1(30d) | P0-1~5 | 1R+1Q+2P |
| M6-3 | Answer-first 콘텐츠 전환 | 1(30d) | P0-6~15 | 1R+1Q+2P |
| M6-4 | Proof-first 신뢰 강화 | 1(30d) | P0-16~25 | 1R+1Q+2P |
| M6-5 | 측정 체계 & 실험 설계 | 1(30d) | P0-26~28 | 1R+1Q+2P |
| M6-6 | 허브-스포크 팬아웃 확장 | 2(60d) | P1-1~20 | 1R+1Q+2P |
| M6-7 | 권위 구축 & AI Validator 자동화 | 3(90d) | P2-1~11 | 1R+1Q+2P |
| M6-8 | 종합 평가 | 전체 | All 59 | 1R+2Q+1P |

> **Note**: 아래 §2의 상세 설계는 v1.0(기능별 7모듈)으로 작성됨.
> 실제 seed.py 구현은 위 8모듈 Phase-순차 구조를 따르며, plan 파일 참조:
> `C:\Users\admin\.claude\plans\snoopy-enchanting-flask.md`

---

## 2. 모듈별 상세 설계

### **M6-1: 운영 킥오프 & 역할 정렬** (Governance & Setup)

**목표**: 팀 구조, 주간 리듬, 산출물 형식, KPI 베이스라인을 **첫 주**에 고정해 실행 병목 제거

**커버 티켓**: P0-1~P0-5 (Tech Infrastructure 기초), P0-26~P0-28 (Measurement Setup)

**커버 섹션**: §1 (Current State), §3.1 (Phase 1 Tech Infrastructure), §7 (Measurement & Experiment)

#### 스텝 구성

**Step 1.1: Reading — "실무 킥오프 가이드: RACI와 주간 운영 리듬"** (순서: 1)

**목표**: 운영 거버넌스의 5가지 필수 요소를 학습하고, 팀이 첫 주에 작성할 체크리스트 제공

**콘텐츠 구조**:
```
## 실무 킥오프 가이드

### 1) 권장 역할 (B2B GEO 운영 기준) - RACI 표
- Owner (A): B2B 마케팅 리드
- Responsible (R): 콘텐츠 담당, 웹 운영 담당
- Consulted (C): 데이터 분석 담당, 세일즈 운영
- Informed (I): 경영진, 영업 리더

### 2) 주간 리듬 (권장)
- 월: KPI/이슈 리뷰 30분
- 화~목: 페이지 개선 + 배포
- 금: AI Validator 점검 + 백로그 확정

### 3) 킥오프 체크리스트 (첫 주 산출물)
- 기준 페이지 5개 확정
- KPI 3층 베이스라인 입력
- 리포트 템플릿 준비
- 승인 SLA 합의

### 4) 복붙용 주간 운영 템플릿
[상세 템플릿]

### 5) 1주차 산출물 체크리스트
- RACI 표 1부
- 4주 실행 캘린더
- 우선순위 백로그 Top 10
```

**Visual Components**:
- `.hierarchy-box`: RACI 표 시각화
- `.flow-chart`: 주간 리듬 (Mon-Fri 일정)
- `.code-example`: 주간 운영 템플릿 복붙 코드
- `.callout`: "킥오프 완료 전에는 다음 모듈로 진행하지 마세요" 경고

**Extension MD**:
- RACI 표 작성 예시 (b2b.fastcampus 기준)
- KPI 베이스라인 입력 구글 시트 링크
- 주간 회의 어젠다 템플릿

---

**Step 1.2: Quiz — "RACI 설계에서 가장 먼저 확정할 항목"** (순서: 2)

**문제 유형**: 실행 병목 우선순위 판단

**문제**:
```
과업 시작 시 RACI에서 가장 먼저 확정해야 할 항목은 무엇인가요?
```

**선택지 및 피드백**:

| 선택 | 텍스트 | 정답 | 피드백 |
|------|--------|------|--------|
| A | 문서 폰트와 색상 규칙 | N | 문서 서식도 중요하지만 실행 지연의 핵심 원인은 책임 불명확입니다. 먼저 최종 의사결정 권한자와 승인 SLA를 확정해야 합니다. |
| B | 최종 의사결정 권한자(Owner)와 승인 SLA | Y | 정답입니다! Owner와 승인 SLA가 먼저 고정되어야 콘텐츠, 개발, 배포 과업이 병목 없이 진행됩니다. 역할 모호성은 가장 빈번한 일정 지연 원인입니다. |
| C | 세부 KPI 수치만 먼저 확정 | N | KPI는 중요하지만 책임 구조가 없으면 실행되지 않습니다. 먼저 Owner와 승인 흐름을 고정한 뒤 KPI를 운영 리듬에 연결해야 합니다. |
| D | 월간 보고서 디자인 | N | 보고서 디자인은 마지막 단계입니다. 킥오프에서는 의사결정 체계와 주간 실행 리듬을 먼저 세팅해야 실제 과업이 움직입니다. |

**설계 의도**: 팀이 "이론"이 아니라 "누가 결정하는가"를 먼저 학습하도록 강제

---

**Step 1.3: Practice — "1주차 우선순위 배치"** (순서: 3)

**문제 유형**: 순서 결정 시나리오

**시나리오**:
```
아래 중 1주차 과업 우선순위로 가장 적절한 순서는 무엇인가요?
```

**선택지**:

| 선택 | 순서 | 정답 | 피드백 |
|------|------|------|--------|
| A | 디자인 리뉴얼 → 채널 확장 → KPI 정의 | N | 디자인 리뉴얼을 선행하면 실행 핵심인 측정 체계와 역할 정렬이 지연됩니다. 1주차는 운영 구조와 기준 페이지 확정이 먼저입니다. |
| B | RACI 확정 → 기준 페이지 5개 선정 → KPI 베이스라인 입력 | Y | 정답입니다! 실행의 시작은 책임 구조, 대상 페이지, 측정 기준을 순서대로 고정하는 것입니다. |
| C | 오프사이트 배포 → 내부링크 수정 → 스키마 검증 | N | 기초 운영 구조 없이 배포부터 시작하면 원인 분석이 불가능해집니다. |
| D | AI Validator 실행 → 보고서 공유 → 목표 논의 | N | 측정 도구 실행은 가능하지만 목표와 역할이 먼저 확정되어야 데이터 해석이 가능합니다. |

---

**Step 1.4: Practice — "킥오프 완료 기준 판단"** (순서: 4)

**문제 유형**: 완료 기준 판단 (최소 조건 조합)

**시나리오**:
```
다음 중 Stage 6 킥오프를 '완료'로 볼 수 있는 최소 조건 조합은 무엇인가요?
```

**선택지**:

| 선택 | 조합 | 정답 | 피드백 |
|------|------|------|--------|
| A | 담당자 명단만 작성 | N | 담당자 명단만으로는 실행 조건이 부족합니다. |
| B | RACI + 기준 페이지 5개 + KPI 베이스라인 + 승인 SLA | Y | 정답입니다! 이 4가지가 고정되어야 과업 실행, 성과 리뷰, 의사결정이 같은 기준으로 돌아갑니다. |
| C | 주간 회의 시간만 합의 | N | 회의 시간 합의만으로는 실행이 시작되지 않습니다. |
| D | 성과 목표 없이 과업 목록만 작성 | N | 성과 목표 없이 과업만 나열하면 우선순위가 흔들립니다. |

---

### **M6-2: 서비스 페이지 리모델링 과업** (Page Structure Optimization)

**목표**: `/service_custom`을 GEO 응답 친화형으로 재구성하는 실행 절차를 학습하고, 다른 9개 상위 랜딩에 확산 가능하도록 템플릿화

**커버 티켓**: P0-6~P0-15 (Answer-first 10개 페이지), P0-16~P0-25 (Proof-first 10개 페이지)

**커버 섹션**: §2.2 (Phase 1 Priority Mapping), §4.1~§4.2 (Hub/Spoke Templates), §8.1 (Answer-first 3 Variants)

#### 스텝 구성

**Step 2.1: Reading — "service_custom 리모델링 상세 가이드"** (순서: 1)

**목표**: Answer-first + Proof-first를 적용한 완전한 SOP를 제공해 팀이 즉시 실행 가능하도록 함

**콘텐츠 구조**:
```
## service_custom 리모델링 상세 가이드

### 실행 순서 (반드시 이 순서대로)

1. 정의문 추가 (AI Validator에서 즉시 인용되는 부분)
   - "기업 맞춤형 생성형 AI 교육이란" 3~4문장
   - 필드: 정의 → 대상 → 방식 → 성과 → 다음단계
   - 위치: H1 바로 아래

2. Answer-first 요약 5줄
   - 문장 1: 누구를 위한가
   - 문장 2: 어떤 방식인가
   - 문장 3: 기간은 얼마나 되는가
   - 문장 4: 어떤 성과를 기대하는가
   - 문장 5: 다음 행동은 무엇인가

3. FAQ 5개 (우선 순위 순)
   - 폐쇄망 환경에서 가능한가
   - 직무별로 다르게 교육하는가
   - 기간과 비용은
   - 성과를 어떻게 측정하는가
   - 맞춤형 교육 vs 표준형 교육의 차이

4. 검증 링크 추가
   - refer_customer 페이지로 이동하는 앵커 텍스트 3개
   - CTA 직전 배치

### 콘텐츠 원칙

- 과장 대신 근거 기반 문장 사용
- 문단당 핵심 주장 1개
- 동일 질문 답변은 사이트 전체에서 일관성 유지

### 완료 정의(DoD)

체크리스트:
- [ ] 상단 20% 영역에 핵심 요약 존재
- [ ] FAQ 최소 5개와 내부링크 2개 이상 반영
- [ ] 수정 전/후 스냅샷 저장
- [ ] 5인 이상 리뷰 통과 (마케팅/편집/운영 각 1인)

### 실무용 문구 템플릿

정의문 템플릿:
"기업 맞춤형 생성형 AI 교육은 [대상 직급/부서]의 [구체적 업무 과제]를 해결하기 위해
직무별 실습과 현업 데이터 기반 코칭을 결합한 교육 방식입니다."

5줄 요약 템플릿:
1) 누구를 위한 교육인가: [직급/역량 레벨]
2) 어떤 방식으로 진행되는가: [강의 구성: 온라인/오프라인/하이브리드]
3) 어느 기간 안에 적용되는가: [총 시수/기간]
4) 어떤 성과를 기대할 수 있는가: [측정 지표]
5) 다음 행동은 무엇인가: [문의 폼/데모 요청]
```

**Visual Components**:
- `.flow-chart`: 리모델링 순서 (정의문 → Answer-first → FAQ → 검증 링크 → CTA)
- `.code-example`: 정의문/5줄 요약/FAQ 템플릿 복붙 코드
- `.browser-mockup`: 모바일/데스크톱에서 "상단 20%" 영역 스크린샷
- `.hierarchy-box`: DoD 체크리스트 시각화
- `.callout`: "Answer-first는 H1 직하에만 배치하세요"

**Extension MD**:
- /service_custom, /service_online 등 각 페이지별 Answer-first 예시 (3개)
- 5줄 요약 작성 금지 사항 (과장, 모호한 표현)
- Before/After 스냅샷 저장 경로 및 방법

---

**Step 2.2: Quiz — "리모델링 우선순위의 핵심"** (순서: 2)

**문제**:
```
service_custom 개선에서 가장 먼저 적용해야 하는 요소는 무엇인가요?
```

**선택지 및 피드백**:

| A | 페이지 전체 애니메이션 교체 | N | 시각 요소 개선은 보조적입니다. 우선은 정의문과 Answer-first 요약처럼 AI와 사용자 모두가 즉시 이해할 수 있는 정보 구조를 먼저 고정해야 합니다. |
| B | 정의문 + Answer-first 요약 + FAQ의 정보 구조 | Y | 정답입니다! GEO 실행 초반에는 정보 구조가 가장 큰 영향력을 가집니다. |
| C | 광고 배너와 팝업 추가 | N | 광고 요소는 오히려 정보 집중을 저해할 수 있습니다. |
| D | SNS 공유 버튼 위치 변경 | N | SNS 버튼은 유통 단계의 보조 요소입니다. |

---

**Step 2.3: Practice — "섹션 배치 순서 설계"** (순서: 3)

**시나리오**:
```
다음 중 service_custom 상단 섹션 배치 순서로 가장 적절한 것은 무엇인가요?
```

**선택지**:

| A | 고객 후기 → 회사 연혁 → 문의 폼 → 정의문 | N | 정의문이 뒤로 밀리면 AI와 사용자가 핵심 맥락을 늦게 파악합니다. |
| B | 정의문 → 5줄 요약 → FAQ → 사례 링크 → CTA | Y | 정답입니다! 질문에 대한 즉답을 먼저 제시하고 검증과 행동으로 이어지는 흐름입니다. |
| C | 문의 폼 → 가격표 → FAQ → 정의문 | N | 행동 요소를 먼저 배치하면 맥락이 부족해 이탈이 증가합니다. |
| D | 블로그 카드 모음 → 팝업 → 정의문 → FAQ | N | 관련 없는 블록을 상단에 과도하게 배치하면 핵심 질문 응답력이 약화됩니다. |

---

**Step 2.4: Practice — "CTA-검증 링크 연결"** (순서: 4)

**시나리오**:
```
전환 직전 신뢰를 높이기 위한 CTA 구성으로 가장 적절한 것은 무엇인가요?
```

**선택지**:

| A | 지금 바로 문의 버튼만 단독 노출 | N | 즉시 문의 버튼만 노출하면 근거가 부족해 의사결정 장벽이 남습니다. |
| B | CTA 직전에 refer_customer 검증 링크를 배치 | Y | 정답입니다! 행동 직전 검증 근거를 제시하면 신뢰와 설득력이 상승합니다. |
| C | CTA 대신 SNS 팔로우 버튼 배치 | N | SNS 팔로우는 전환 행동이 아닙니다. |
| D | CTA를 페이지 최하단 1회만 배치 | N | 최하단 단일 CTA만으로는 도달률이 낮아집니다. |

---

### **M6-3: 스키마 구현 & 검증 과업** (Schema Implementation & QA)

**목표**: BreadcrumbList, Article, Event 스키마 배포 → 검증 → 배포 4단계를 표준화하고, QA 실패 패턴을 학습

**커버 티켓**: P0-3~P0-4 (Schema Audit), P1-4, P1-8, P1-15, P1-19 (Case Study/Event schemas), P2-1~P2-5 (Organization/BreadcrumbList/FAQPage deployment)

**커버 섹션**: §1.1 (Structured Data Status), §3.1 (Phase 1 Tech), §8.3~§8.5 (Templates)

#### 스텝 구성

**Step 3.1: Reading — "스키마 구현 실행 체크리스트"** (순서: 1)

**목표**: 4단계 검증 파이프라인과 실패 대응 원칙을 명확히 해서, "배포 후 재검증"을 습관화

**콘텐츠 구조**:
```
## 스키마 구현 실행 체크리스트

### 스키마 4단계 검증 파이프라인 (필수 순서)

#### 단계 1: 로컬 코드 리뷰
- 필수 필드 누락 확인
- 데이터 타입 정확성 확인
- JSON-LD 문법 유효성 (JSON Lint 도구)
- 체크리스트:
  [ ] @context 명시
  [ ] @type 정확
  [ ] 필수 필드 모두 포함
  [ ] 선택 필드는 의도한 필드만 포함

#### 단계 2: Rich Results Test (Google)
- Google Search Central 도구 사용
- 리치 리절트 적격성 확인
- 경고/오류 발견
- 보정 필요사항 식별

#### 단계 3: Schema Markup Validator
- schema.org 기준 문법 검증
- JSON 그래프 정확성
- 타입 호환성 확인
- 체크:
  [ ] 모든 속성이 해당 타입에 존재
  [ ] 중첩 객체 구조 정확
  [ ] Enum 값이 정의된 범위 내

#### 단계 4: URL Inspection (배포 후)
- 실제 URL 크롤 & 렌더링
- HTML 반영 여부 확인
- 동적 렌더링 이슈 탐지
- 최종 배포 승인

### 페이지별 우선 타입

| 페이지 | 필수 스키마 | 조건부 스키마 |
|--------|-----------|----------|
| service_custom | BreadcrumbList | Organization, Article |
| resource_insight_* | Article | BreadcrumbList |
| resource_seminar_* | Event | BreadcrumbList |
| refer_customer_* | Event (Case Study) | Article, BreadcrumbList |

### 실패 대응 원칙

- [ ] 오류가 1개라도 남아 있으면 배포 보류
- [ ] 타입 오남용 (예: Contact에 Course) 발견 시 즉시 롤백
- [ ] QA 로그를 남겨 다음 배포에서 재발 방지

### QA 기록 템플릿 (Copy-paste 가능)

```
URL: [대상 페이지 URL]
Schema Type: [타입명]
필수 필드 체크: PASS/FAIL
  - 필드1: [내용]
  - 필드2: [내용]

Rich Results Test 결과: [PASS/WARN/FAIL] + 스크린샷
Schema Validator 결과: [결과 요약]
URL Inspection 결과: [렌더링 성공/실패]

조치 내용: [어떤 부분을 수정했는가]
재검증 일시: [YYYY-MM-DD HH:MM]
```

### 자주 하는 실수 패턴

1. **Rich Results 합격 후 배포 생략**
   - 실제 URL에서 렌더링 안 될 수 있음 → URL Inspection 필수

2. **Contact 페이지에 Course 스키마 그대로 사용**
   - 현재 상태: 25개 페이지 모두 Course 마크업 (오용)
   - 수정: ContactPage로 변경

3. **Event 스키마에 startDate 누락**
   - 세미나 페이지는 반드시 startDate + location 포함

4. **BreadcrumbList 경로가 실제 IA와 불일치**
   - 구조화 데이터는 실제 허브-스포크 내부링크와 일치해야 함
```

**Visual Components**:
- `.flow-chart`: 4단계 검증 파이프라인 (Code Review → Rich Results → Validator → URL Inspection)
- `.code-example`: QA 기록 템플릿
- `.hierarchy-box`: 페이지별 우선 스키마 테이블
- `.callout`: "배포 전 4단계 모두 완료하세요" + "현재 상태: Contact→Course 오용 25개 페이지"
- `.diagram-box`: 스키마 오류 → 롤백 의사결정 트리

**Extension MD**:
- 각 스키마 타입별 필수 필드 체크리스트 (BreadcrumbList, Article, Event, Organization, FAQPage)
- Google Rich Results Test 오류 메시지별 대응 가이드
- URL Inspection에서 "Excluded by robots.txt" vs "Not indexed" 차이점

---

**Step 3.2: Quiz — "검증 도구의 올바른 조합"** (순서: 2)

**문제**:
```
스키마 배포 전 검증 조합으로 가장 정확한 것은 무엇인가요?
```

**선택지**:

| A | Rich Results Test 하나만 사용 | N | 한 가지 도구만으로는 누락 이슈를 충분히 걸러내기 어렵습니다. |
| B | Rich Results Test + Schema Validator + URL Inspection | Y | 정답입니다! 세 도구를 함께 사용하면 리치리절트 적합성, 문법 유효성, 실제 렌더 반영 여부를 모두 점검할 수 있습니다. |
| C | 브라우저 화면 확인만으로 충분 | N | 브라우저 화면은 시각적 표현만 확인할 수 있고, JSON-LD 파싱은 별도 검증이 필요합니다. |
| D | 로컬 코드 리뷰만으로 충분 | N | 로컬 검증 후에도 배포 환경에서 렌더링 실패할 수 있으므로 URL Inspection이 필수입니다. |

---

**Step 3.3: Practice — "타입 오남용 탐지"** (순서: 3)

**시나리오**:
```
현재 b2b.fastcampus.co.kr은 Contact 페이지(/contact, /contact_mktg)에 모두 @type:Course를 사용하고 있습니다.
이 문제를 가장 효과적으로 해결하는 방안은 무엇인가요?
```

**선택지**:

| A | 그냥 두어도 문제없다 | N | Google은 명확한 페이지 타입을 선호합니다. Course는 교육 콘텐츠용이므로 Contact에 적용하면 신뢰도 신호가 약화됩니다. |
| B | Contact 페이지는 ContactPage로, Course 페이지는 Course로 분리 | Y | 정답입니다! 각 페이지의 실제 의도에 맞는 스키마를 적용해야 Google의 이해도와 리치 리절트 노출 가능성이 높아집니다. |
| C | 모든 페이지를 WebPage로 통일 | N | WebPage는 가장 일반적인 타입으로, 더 구체적인 타입(ContactPage, Course)의 기회를 잃게 됩니다. |
| D | 스키마를 완전히 제거 | N | 스키마 제거는 AI 검색 엔진이 페이지를 이해하기 더 어렵게 만듭니다. |

---

**Step 3.4: Practice — "QA 로그 기록 시나리오"** (순서: 4)

**시나리오**:
```
/service_custom 페이지에 BreadcrumbList 스키마를 배포했는데,
Rich Results Test는 통과했으나 URL Inspection에서 "rendering" 오류가 발생했습니다.
가장 적절한 다음 조치는 무엇인가요?
```

**선택지**:

| A | Rich Results 통과했으니 배포 완료 | N | URL Inspection 오류는 실제 환경에서 JSON-LD가 렌더링되지 않았음을 의미합니다. 배포 전에 오류를 해결해야 합니다. |
| B | 코드 재검토 → robots.txt 확인 → URL 다시 제출 후 재검증 | Y | 정답입니다! Rendering 오류는 JS 렌더링 지연이나 robots 제외 때문일 수 있습니다. 코드 검토 후 재제출이 표준 대응입니다. |
| C | 다른 페이지를 먼저 진행하고 나중에 해결 | N | 스키마 오류가 있는 상태로 배포하면 Google이 잘못된 신호를 학습할 수 있습니다. |
| D | 스키마를 완전히 제거하고 다시 진행 | N | 제거보다는 디버깅이 빠릅니다. 오류 원인을 파악하는 것이 우선입니다. |

---

### **M6-4: 허브-클러스터 내부링크 과업** (IA & Internal Links)

**목표**: 7개 허브 중심의 사이트 구조를 명시하고, 스포크 간 상호 링크로 "주제 전문성" 신호를 강화

**커버 티켓**: P1-16~P1-18 (3 Batches of Internal Linking), P2-6~P2-7 (IA Redesign + Spoke Auto-linking)

**커버 섹션**: §1.3 (Internal Link Structure), §4.2 (Hub-Spoke Format), §8.3~§8.4 (Templates)

#### 스텝 구성

**Step 4.1: Reading — "허브-스포크 IA 맵 설계 및 내부링크 표준화"** (순서: 1)

**목표**: 현재 Flat 구조(평면형)에서 Hub-Spoke 구조로 재설계하는 실행 SOP를 제공

**콘텐츠 구조**:
```
## 허브-스포크 IA 맵 설계 및 내부링크 표준화

### 1) 현재 문제 상태 (§1.3 기반)

| 문제 | 영향 |
|------|------|
| 평면형 구조 (Flat) | 모든 페이지가 홈, 문의, 개인정보로만 연결 |
| 서비스 페이지 고립 | service_custom, service_online이 서로 연결 안 됨 |
| 사례 허브 미활용 | refer_customer가 다른 사례/관련 페이지 연결 안 됨 |
| 주제 전문성 약함 | 관련 페이지들이 명시적으로 연결 안 됨 |

### 2) 목표 구조 (Hub-Spoke)

#### 허브 7개 중심 설계

```
홈 (Index) [모든 허브로의 네비게이션]
│
├─ Hub 1: 기업 AI 교육 도입 가이드
│  ├─ Spoke 1-1: 도입 체크리스트
│  ├─ Spoke 1-2: RFP 템플릿
│  ├─ Spoke 1-3: 보안 고려사항
│  └─ [Spoke 1-10]
│
├─ Hub 2: 스킬 진단·HRD
│  ├─ Spoke 2-1: IDP 템플릿
│  ├─ Spoke 2-2: 스킬 매트릭스
│  └─ [Spoke 2-8]
│
├─ Hub 3: 교육 ROI·애널리틱스
├─ Hub 4: LMS/LXP 플랫폼 선택
├─ Hub 5: 직무별 AI 활용
├─ Hub 6: 폐쇄망·보안 교육
└─ Hub 7: 벤치마크·사례
```

### 3) 내부링크 표준화 규칙

#### 링크 유형 3가지

1. **Hub → Spoke 링크** (계층적 네비게이션)
   - 위치: 허브 페이지 본문, "관련 스포크" 섹션
   - 텍스트: 설명적 앵커 (예: "IDP 템플릿 다운로드" vs "여기")
   - 개수: 최소 3개 이상
   - 예시: `/hub_skill_diagnosis` → `/spoke_idp_template`

2. **Spoke → Hub 역링크** (컨텍스트 제공)
   - 위치: 스포크 페이지 상단 또는 "관련 가이드" 섹션
   - 텍스트: "스킬 진단·HRD 완전 가이드" (Breadcrumb 느낌)
   - 개수: 1개
   - 예시: `/spoke_idp_template` → `/hub_skill_diagnosis`

3. **Spoke ↔ Spoke 상호링크** (주제 깊이)
   - 위치: "다음 읽기" 또는 "관련 주제" 박스
   - 텍스트: 설명적 ("개인별 학습계획 수립 방법" vs "다음")
   - 개수: 3~5개 관련 스포크
   - 예시: `/spoke_idp_template` → [`/spoke_skill_matrix`, `/spoke_skill_level`, `/spoke_role_model`]

### 4) 앵커 텍스트 작성 가이드

❌ 하지 말 것:
- "여기를 클릭하세요"
- "더보기"
- "링크"

✅ 해야 할 것:
- "IDP(개인별 학습계획) 템플릿 다운로드"
- "스킬 매트릭스 작성 가이드"
- "조직 전환 단계별 로드맵"

### 5) 내부링크 QA 체크리스트

- [ ] 모든 허브 페이지가 홈에서 네비게이션 가능
- [ ] 모든 스포크가 상위 허브로 역링크
- [ ] 스포크 간 상호링크: 3개 이상 (관련도 기준)
- [ ] 앵커 텍스트 100% 설명적 (단어 3개 이상)
- [ ] 404 링크 0개
- [ ] 순환링크 없음 (A→B→C→A 같은 순환)

### 6) 운영 리듬

- **주 1회**: 신규 스포크 발행 시 관련 스포크/허브 링크 2개 최소 추가
- **월 1회**: 전체 내부링크 체크 (404 여부, 앵커 텍스트 품질)
- **분기 1회**: IA 맵 업데이트 (새 허브/스포크 반영)
```

**Visual Components**:
- `.diagram-box`: Hub-Spoke 트리 구조 (7개 허브, 60개 스포크)
- `.hierarchy-box`: 링크 유형 3가지 테이블 (Hub→Spoke / Spoke→Hub / Spoke↔Spoke)
- `.code-example`: 앵커 텍스트 ❌/✅ 예시 리스트
- `.flow-chart`: QA 체크리스트 (월/분기 리듬)
- `.callout`: "설명적 앵커 텍스트는 SEO와 접근성을 동시에 개선합니다"

**Extension MD**:
- 현재 상태 분석: 페이지당 내부링크 평균 41개 (모두 홈/문의/개인정보로 수렴)
- 허브 7개별 권장 스포크 리스트 (§4.2에서 발췌)
- 링크 매트릭스 템플릿 (행: 페이지, 열: 링크 대상)

---

**Step 4.2: Quiz — "앵커 텍스트 설명적 표현"** (순서: 2)

**문제**:
```
다음 중 SEO와 사용자 경험을 동시에 개선하는 앵커 텍스트는 무엇인가요?
```

**선택지**:

| A | "여기를 클릭" | N | 앵커 텍스트가 링크 목적을 설명하지 않아 AI도 혼동하고 사용자도 클릭할 동기가 약합니다. |
| B | "IDP(개인별 학습계획) 템플릿 다운로드하기" | Y | 정답입니다! 링크 목적이 명확하므로 AI 검색 엔진이 주제를 이해하기 쉽고, 사용자도 클릭 여부를 판단하기 쉽습니다. |
| C | "링크" | N | 가장 일반적인 표현으로, 링크 의도를 전혀 전달하지 않습니다. |
| D | "스킬" | N | 너무 짧고 모호해서 링크 컨텍스트를 제공하지 않습니다. 최소 3개 단어 이상이 좋습니다. |

---

**Step 4.3: Practice — "Hub-Spoke 링크 배치 우선순위"** (순서: 3)

**시나리오**:
```
새로운 spoke 페이지 "/spoke_idp_template"을 발행했습니다.
가장 먼저 해야 할 내부링크 작업은 무엇인가요?
```

**선택지**:

| A | 모든 스포크(60개)와 상호링크 | N | 모든 스포크와 연결하면 link juice가 과도하게 분산되고, 관련도가 떨어집니다. 가장 관련 높은 3~5개만 선정해야 합니다. |
| B | 상위 허브(/hub_skill_diagnosis)로 역링크 + 관련 스포크 3개 상호링크 | Y | 정답입니다! 먼저 계층적 구조(spoke→hub)를 명시한 뒤, 같은 주제 스포크끼리 연결하는 순서가 리소스 효율적입니다. |
| C | 홈(/index) 페이지에만 링크 추가 | N | 홈 링크도 필요하지만, 상위 허브를 거쳐서 도달하는 것이 IA 신호에 더 효과적입니다. |
| D | 일단 발행한 후 3개월 뒤 링크 작업 | N | 내부링크는 발행 직후가 가장 효과적입니다. 지연하면 검색 봇이 새 페이지를 발견하기까지 시간이 더 걸립니다. |

---

**Step 4.4: Practice — "순환링크 회피"** (순서: 4)

**시나리오**:
```
현재 다음과 같은 내부링크 구조가 있습니다:
- /spoke_idp → /spoke_skill_matrix (링크 O)
- /spoke_skill_matrix → /spoke_role_model (링크 O)
- /spoke_role_model → /spoke_idp (링크 O)

이 구조의 문제점은 무엇이고, 어떻게 개선해야 하나요?
```

**선택지**:

| A | 순환링크는 문제없다 | N | 순환링크(A→B→C→A)는 link crawl budget을 낭비하고, 사용자 경험에서 혼동을 일으킵니다. |
| B | 순환을 끊고 계층적으로 재설계: 모두 hub_skill_diagnosis로 역링크 | Y | 정답입니다! Hub를 중심으로 Spoke들이 방사형으로 연결되어야 명확한 주제 구조를 형성합니다. |
| C | 더 많은 페이지를 순환에 추가 | N | 순환을 더 크게 만들면 문제가 더 심해집니다. |
| D | 내부링크를 모두 제거 | N | 제거보다는 재구조화가 해결책입니다. |

---

### **M6-5: 오프사이트 배포 & 멘션 과업** (Off-site Distribution & Authority)

**목표**: 월간 3건 이상의 PR/멘션/소셜 배포를 체계화하고, UTM 추적으로 채널별 성과를 측정

**커버 티켓**: P2-9~P2-11 (External Authority: Original Reports, Customer Co-cases, Media Bylines)

**커버 섹션**: §5.3 (Phase 3 External Authority), §7 (Measurement with utm tracking), §8.6 (Weekly Citation Log)

#### 스텝 구성

**Step 5.1: Reading — "오프사이트 배포 월간 운영 캘린더 설계"** (순서: 1)

**목표**: 단발 캠페인이 아니라 월간 반복 가능한 배포 시스템을 구축하고, 각 채널별 최소 실행량 정의

**콘텐츠 구조**:
```
## 오프사이트 배포 월간 운영 캘린더 설계

### 1) 채널별 최소 실행량 (월간)

| 채널 | 목표 | 빈도 | 자산 유형 | 예상 효과 |
|------|------|------|---------|---------|
| PR (보도자료) | 최소 1건 | 월 1회 | 리포트 발행, 세미나, CEO 인터뷰 | 브랜드 신뢰도 + 역링크 |
| 업계 매체 기고 | 최소 1건 | 월 1회 | 인사이트, 벤치마크 분석 | Authority 신호 + 트래픽 |
| 협회/포럼 멘션 | 최소 1건 | 월 1~2회 | HR/기업교육 협회, 포럼 댓글 | Community 신뢰도 + 트래픽 |
| 소셜(LinkedIn) | 최소 3건 | 주 1회 | 스포크 요약, 팁, 케이스 스냅샷 | 리치 + 유입 |

### 2) 월간 배포 캘린더 템플릿

```
[2026년 3월 오프사이트 배포 계획]

주 1 (3/1~3/7):
- 월(3/1): PR 작성 시작 (리포트 1호 "기업 AI 교육 2026 트렌드")
- 수(3/3): LinkedIn 포스트 1 (스포크 요약 #IDP)
- 금(3/5): 내부 리뷰 & 편집

주 2 (3/8~3/14):
- 월(3/8): PR 배포 (보도자료 배포 네트워크)
- 수(3/10): 업계 매체 기고 투고 (HR Korea 매거진)
- 금(3/12): LinkedIn 포스트 2 (케이스 스냅샷)

주 3 (3/15~3/21):
- 월(3/15): 협회 기고 리뷰 (대기업교육연합회)
- 수(3/17): LinkedIn 포스트 3 (팁/체크리스트)
- 금(3/19): 링크 추적 확인 (역링크, utm 수집)

주 4 (3/22~3/31):
- 월(3/22): 다음 월 자산 준비 (콘텐츠 확정)
- 수(3/24): 포럼/커뮤니티 답변 (LinkedIn Groups, 블로그)
- 금(3/29): 월간 회고 & 다음 월 계획
```

### 3) 자산별 배포 매칭 기준

#### A) 오리지널 리포트
- 배포처: PR 1차, 업계 매체 인터뷰/기사화, 협회 공식 채널
- UTM: `utm_source=press_release&utm_campaign=report_2026_q1`
- 예상 역링크: 5~10개 (매체 언급, 협회 소개)

#### B) 고객 공동 케이스 (Co-authored)
- 배포처: 고객사 PR, 업계 매체 (case study 섹션), LinkedIn
- UTM: `utm_source=customer_case&utm_campaign=[고객명]`
- 예상 역링크: 2~3개 + 고객사 내부 공유

#### C) 협회/포럼 멘션
- 배포처: 협회 웹사이트, LinkedIn 그룹, 산업 포럼
- UTM: `utm_source=association&utm_campaign=[협회명]`
- 예상 트래픽: 월 50~150 uniques

#### D) 소셜 (LinkedIn)
- 배포처: 회사 계정 + 직원 개인 계정 (권유)
- UTM: `utm_source=linkedin&utm_campaign=[콘텐츠타입]`
- 예상 리치: 포스트당 1K~5K

### 4) UTM 표준화

**기본 형식**:
```
https://b2b.fastcampus.co.kr/[page]?utm_source=[source]&utm_campaign=[campaign]&utm_content=[콘텐츠명]
```

| 변수 | 값 | 예시 |
|------|----|----|
| utm_source | PR, Media, LinkedIn, Association, Referral | `utm_source=press_release` |
| utm_campaign | 분기/테마 | `utm_campaign=report_2026_q1`, `utm_campaign=ai_education_adoption` |
| utm_content | 구체적 콘텐츠 | `utm_content=idp_template`, `utm_content=case_study_samsung` |

**금지된 패턴**:
- ❌ `utm_source=direct`
- ❌ 한글 문자 (인코딩 오류 유발)
- ❌ 대문자 (GA 필터 혼동)

### 5) 월간 추적 및 리포팅

| 지표 | 측정 방법 | 목표 |
|------|---------|------|
| PR 역링크 수 | Ahrefs / SEMrush | 월 2개 이상 |
| 기고 게시 여부 | 매체 확인 검색 | 월 1개 이상 |
| LinkedIn 리치 | GA4 utm_source=linkedin | 월 5K+ |
| 협회 트래픽 | GA4 utm_source=association | 월 100+ |

### 6) 4주 리포트 템플릿

```
[2026년 3월 오프사이트 배포 리포트]

실행 요약:
- PR 배포: 1건 (기업 AI 교육 2026 리포트)
- 기고 게시: 1건 (HR Korea 매거진)
- 협회 언급: 2건 (대기업교육연합회, HRD Forum)
- LinkedIn 포스트: 3건

트래픽 결과:
- PR → 유입: 234 sessions (avg. bounce 45%)
- Media → 유입: 156 sessions
- Association → 유입: 89 sessions
- LinkedIn → 유입: 412 sessions

역링크 발굴:
- PR로부터 역링크: 3개 (언론사 2, 협회 1)
- 업계 매체 언급: 2개

다음 월 개선 사항:
- 이번 월 높은 성과 채널 (LinkedIn) 더 강화
- 기고 게시 시간 단축 (목표: 투고 후 10일 내 게시)
```
```

**Visual Components**:
- `.code-example`: 월간 배포 캘린더 템플릿 (복붙 가능)
- `.flow-chart`: 자산 유형별 배포 채널 매칭 (Diagram)
- `.hierarchy-box`: UTM 변수 표준 (utm_source / utm_campaign / utm_content)
- `.callout`: "한글 UTM은 GA 필터링에서 오류 유발 → 영문 사용 필수"
- `.compare-cards`: ✅ UTM 올바른 예 vs ❌ 잘못된 예

**Extension MD**:
- PR 배포 네트워크 리스트 (한국 보도자료 배포처 10개)
- 업계 매체 리스트 (HR, 기업교육, AI 관련 20개)
- LinkedIn 포스트 템플릿 (스포크 요약 버전)
- 역링크 추적 도구 비교 (Ahrefs vs SEMrush vs Moz)

---

**Step 5.2: Quiz — "채널별 배포 자산 매칭"** (순서: 2)

**문제**:
```
신규 리포트 "기업 AI 교육 2026 트렌드"를 발행했습니다.
가장 효과적인 배포 순서는 무엇인가요?
```

**선택지**:

| A | LinkedIn만 공유하고 대기 | N | 리포트 같은 고가치 콘텐츠는 PR → 매체 → 소셜 순서로 배포해야 권위성이 높아집니다. |
| B | PR 배포 → 업계 매체 기고 제안 → LinkedIn 홍보 | Y | 정답입니다! 공식 채널부터 시작해 신뢰도를 확보한 후 소셜 확산하는 순서가 역링크와 브랜드 인지도를 동시에 높입니다. |
| C | 소셜 먼저 공유하고 PR 나중에 | N | 순서를 역으로 하면 매체가 이미 공개된 콘텐츠로 간주해 기고 제안 응률이 낮아집니다. |
| D | 협회에만 공개하고 일반 배포 안 함 | N | 협회 제한 배포는 리포트 가치를 최대한 활용하지 못하는 전략입니다. |

---

**Step 5.3: Practice — "UTM 추적과 성과 분석"** (순서: 3)

**시나리오**:
```
3월 LinkedIn에서 50개 링크 클릭을 받았으나, GA4에서는 utm_source=linkedin인 트래픽이
35개만 기록되었습니다. 원인이 무엇일까요?
```

**선택지**:

| A | GA4가 정확하지 않아서 | N | GA4는 정확합니다. 추적 누락의 원인은 구현 측에서 찾아야 합니다. |
| B | UTM이 없는 클릭, 또는 다른 utm_source로 태그된 클릭이 있을 수 있음 | Y | 정답입니다! LinkedIn 클릭 중 일부는 직접 클릭(utm 없음)이거나, 복사 후 공유(utm 손실)되었을 수 있습니다. 15개 차이는 정상 범위입니다. |
| C | 모든 링크에 UTM을 다시 붙여야 함 | N | 이미 배포된 링크에 UTM을 변경하면 이전 데이터가 끊어집니다. |
| D | LinkedIn 플랫폼 오류 | N | LinkedIn은 정상 작동하고 있고, 추적 차이는 자연스럽습니다. |

---

**Step 5.4: Practice — "4주 리포팅과 다음 월 우선순위"** (순서: 4)

**시나리오**:
```
3월 오프사이트 배포 결과:
- PR 역링크: 1개 (목표 2개)
- 기고 게시: 1개 (목표 1개) ✓
- LinkedIn 리치: 8K (목표 5K) ✓

가장 적절한 4월 전략 조정은 무엇인가요?
```

**선택지**:

| A | PR 개수를 월 2건으로 늘리고, LinkedIn은 줄임 | Y | 정답입니다! LinkedIn은 이미 목표 초과 달성했으므로, 역링크 부족 영역(PR)에 리소스를 집중해야 합니다. |
| B | 모든 채널을 동일하게 유지 | N | 성과 기반 조정이 없으면 리소스 낭비가 발생합니다. |
| C | 성과가 낮은 협회/기고 채널을 완전히 중단 | N | 협회와 기고는 장기 신뢰도를 위해 필요합니다. 완전 중단보다는 방식 개선이 낫습니다. |
| D | LinkedIn은 충분하니 오프사이트 투자 중단 | N | LinkedIn 성과가 좋아도, 역링크(외부 권위)는 AI 검색의 핵심 신호이므로 계속 투자해야 합니다. |

---

### **M6-6: AI Validator & KPI 리포팅 과업** (Measurement Loop)

**목표**: 주간 Top 50 질문 실행 → 인용 로그 기록 → 이슈 에스컬레이션으로 측정-개선 루프를 내재화

**커버 티켓**: P0-26~P0-28 (Measurement Setup), P2-12~P2-14 (AI Validator Automation)

**커버 섹션**: §7 (Measurement & Experiment Design), §8.4 (AI Validator 10 Prompts), §8.6 (Weekly Citation Log)

#### 스텝 구성

**Step 6.1: Reading — "주간 AI Validator 실행 및 인용 로그 작성 SOP"** (순서: 1)

**목표**: ChatGPT Search + Google AI 인용을 주간 2회 실행하고, 패턴을 추적 가능하게 로깅

**콘텐츠 구조**:
```
## 주간 AI Validator 실행 및 인용 로그 작성 SOP

### 1) 측정 대상 3가지 KPI

| KPI | 정의 | 측정 빈도 | 도구 | 목표 |
|-----|------|---------|------|------|
| KPI-A: ChatGPT 인용 빈도 | b2b.fastcampus.co.kr이 ChatGPT Search에서 출처로 노출되는 빈도 | 주 2회 (화/금) | 수동 SERP + utm_source 추적 | 30일 +20% → 90일 +150~200% |
| KPI-B: Google AI 노출 | Google Search AI Mode/Overviews에서 노출 빈도 | 주 1회 (수) | Google Search 수동 검색 | 30일 기준선 → 90일 +80% |
| KPI-C: 하위 질의 커버리지 | 50개 질문 중 Answer+Proof 모두 있는 질문 비율 | 주 1회 (목) | 수동 평가 + AI Validator | 30일 35% → 90일 85%+ |

### 2) 주간 스케줄 (고정)

```
월요일:
- [10:00] KPI 리뷰 30분 (지난주 결과)
- [11:00~12:00] 이슈 분류 (Q: ChatGPT에서 노출 안 된 페이지 3개 선정)

화요일:
- [10:00~11:00] KPI-A 측정: Top 50 질문 × ChatGPT Search
  → 인용 발견 시 스크린샷 + 인용 텍스트 기록
  → b2b.fastcampus 노출 URL 기록

수요일:
- [14:00~15:00] KPI-B 측정: Top 50 질문 × Google AI Mode
  → Google Search에서 AI Mode 전환 후 실행
  → 노출 위치, 인용 문장 기록

목요일:
- [10:00~11:00] KPI-C 측정: 50개 질문별 커버리지 평가
  → 0점 (답변 없음), 1점 (관련 페이지만), 2점 (Answer만), 3점 (Answer+Proof)
  → 커버율 계산 (3점 / 50 = %)

금요일:
- [10:00~11:00] 주간 리포트 작성 + 다음주 우선순위 확정
  → 낙폭 페이지 3개 긴급 개선 백로그 추가
  → 신규 스포크 발행 영향도 분석
```

### 3) Top 50 질문 세트 (§7.3에서 발췌)

**5개 카테고리 × 10 질문 = 50개**:

1. 기업 AI 교육 도입 (10개): 필요성, 시작 방법, 커리큘럼 설계, 역량 평가, 보안, 비용, 담당자 역할, 온/오프라인, 효과 측정, 직무별 차이
2. 직무별 AI 활용 (10개): 영업, HR, 마케팅, 기획, 재무/회계, 법무, 운영, 고객 서비스, 데이터 분석, 경영진
3. 스킬 진단 및 HRD (10개): 진단 방법, 결과 반영, IDP 수립, 이점, 역량 모델, 매트릭스, 레벨 평가, 도구 선택, 실패 패턴, 로드맵
4. 교육 효과 측정 및 ROI (10개): ROI 계산, 지표, 수료율, 업무 적용도, 리포트 내용, 데이터 수집, 학습 경로, 비용 대비 효과, KPI, 실무 활용
5. 플랫폼 선택 및 보안 (10개): LMS 선택, LMS vs LXP, 보안 점검, RFP, 추천 기능, 데이터 마이그레이션, SaaS vs 자체구축, 폐쇄망 운영, 채택률, 정보보안

### 4) 인용 로그 기록 템플릿

```
[주간 AI Validator 인용 로그]

기간: 2026-02-24 ~ 2026-03-02 (Week 09)

**KPI-A: ChatGPT Search 인용**

| 질문 | 노출 여부 | 노출 위치 (상/중/하) | 인용 URL | 인용 텍스트 | 스크린샷 |
|------|---------|------|---------|-----------|--------|
| 기업에서 생성형 AI 교육이 필요한 이유 | Y | 상 | /resource_report | "AI 교육은..." | [링크] |
| IDP(개인별 학습계획)를 어떻게 수립하는가 | Y | 중 | /spoke_idp_template | "IDP 수립 단계..." | [링크] |
| 교육 ROI를 어떻게 계산하는가 | N | - | - | - | - |

노출 페이지 URL 목록:
- /resource_report (3건 인용)
- /spoke_idp_template (2건 인용)
- /service_custom (1건 인용)

미노출 질문 TOP 3:
1. "AI 교육 도입에 얼마나 비용이 들어가는가" (해당 페이지 없음)
2. "스킬 기반 HRD가 실패하는 이유는" (커버리지 부족)
3. "기업 AI 교육 담당자의 역할은 무엇인가" (Answer-first 부족)

**KPI-B: Google AI Overviews/AI Mode 노출**

Google Search "AI 교육 도입 가이드" 검색:
- AI Mode 활성화 여부: O
- b2b.fastcampus 노출: Y / 위치: 3번째
- 인용 텍스트: "[...]기업 맞춤형 AI 교육[...]"
- 스크린샷: [링크]

Google Search "스킬 기반 HRD" 검색:
- AI Overviews 활성화: O
- b2b.fastcampus 노출: N
- 대신 노출 페이지: competitor_site.com (5개 링크)

**KPI-C: 커버리지 평가**

3점 (Answer+Proof 모두): 18개 / 50개 = 36% (목표 35%)
2점 (Answer만): 12개 = 24%
1점 (관련만): 15개 = 30%
0점 (커버 안 됨): 5개 = 10%

커버리지 추세: 2주 전 32% → 1주 전 35% → 금주 36% ✓

**이슈 및 개선 액션**

높은 우선순위 (P0):
- [ ] "AI 교육 비용" 관련 스포크 발행 (월요일 승인 필요)
- [ ] "/resource_report Answer-first" 강화 (현재 약함)
- [ ] "/service_custom Proof 블록" 추가 (출처 2개 누락)

중간 우선순위 (P1):
- [ ] 경쟁사 비교 페이지 작성 (Google Overviews 대응)
- [ ] "직무별 AI 활용" 스포크 내부링크 강화

다음주 목표:
- ChatGPT 인용 +2개 (현재 6 → 목표 8)
- 커버리지 38% 달성
```

**Visual Components**:
- `.flow-chart`: 주간 스케줄 (Mon-Fri 시간별)
- `.hierarchy-box`: KPI 3가지 테이블 (정의 / 측정 빈도 / 도구 / 목표)
- `.code-example`: 인용 로그 템플릿 (복붙 가능 구글 시트)
- `.callout`: "매주 금요일 리포트는 다음주 백로그 의사결정에 직결됩니다"
- `.diagram-box`: 이슈 분류 트리 (P0 / P1 / P2)

**Extension MD**:
- Top 50 질문 전체 리스트 (5개 카테고리 × 10)
- ChatGPT Search vs Google AI 차이점 (검색 시 유의사항)
- 인용 로그 구글 시트 템플릿 링크
- 이슈 에스컬레이션 플로우 (누가 승인하는가)

---

**Step 6.2: Quiz — "커버리지 판정 기준"** (순서: 2)

**문제**:
```
질문 "IDP(개인별 학습계획)를 어떻게 수립하는가"에 대해:
- /spoke_idp_template 페이지가 있음
- 페이지에는 Answer-first (3문장) O
- Proof 블록 (통계 + 출처) X

이 질문의 커버리지 점수는?
```

**선택지**:

| A | 3점 (완전 커버) | N | Proof 블록이 없으므로 2점입니다. AI Validator는 답변 + 근거를 모두 보고 인용합니다. |
| B | 2점 (Answer만) | Y | 정답입니다! Answer-first가 있으므로 "답변하고 있음"이지만, Proof 블록이 없어 신뢰도가 낮습니다. 이 질문은 다음 스프린트에서 Proof 추가 대상입니다. |
| C | 1점 (관련만) | N | 페이지가 정확히 그 주제를 다루고 있으므로 1점보다 높습니다. |
| D | 0점 (커버 안 됨) | N | 답변 페이지가 명확히 있으므로 0점이 아닙니다. |

---

**Step 6.3: Practice — "주간 인용 로그 분석"** (순서: 3)

**시나리오**:
```
2주전 인용 6개 → 1주전 4개 → 금주 3개로 급감했습니다.
이 낙폭의 가장 가능성 높은 원인은?
```

**선택지**:

| A | AI 모델이 우리 페이지를 싫어하게 됨 | N | AI 모델의 선호도는 매주 급격히 바뀌지 않습니다. 원인은 페이지/콘텐츠 변화에 있을 것입니다. |
| B | 경쟁사가 더 강한 Answer-first 콘텐츠를 발행해 순위가 밀려남 | Y | 정답입니다! 인용 감소는 대부분 경쟁 콘텐츠 발행 또는 우리 페이지 품질 저하 때문입니다. 경쟁사 분석과 우리 페이지 Answer-first 강화를 긴급 액션으로 제안해야 합니다. |
| C | 측정 방식이 잘못되었음 | N | 측정은 일관되었고, 수치 추적도 정확합니다. |
| D | 크롤링 오류 | N | 크롤링 오류는 갑작스럽지 않으며, 이 정도 낙폭을 설명하기 어렵습니다. |

---

**Step 6.4: Practice — "이슈 우선순위 판정"** (순서: 4)

**시나리오**:
```
금주 인용 로그에서 발견된 이슈:

1. "AI 교육 비용" 질문 미노출 (매우 높은 검색량 예상)
2. "경쟁사 비교" 질문 노출되나 우리 링크 없음 (Google Overviews에만)
3. "/service_custom Proof 블록" ChatGPT에서 2주 연속 비노출

우선순위 순서는?
```

**선택지**:

| A | 1 → 2 → 3 (모두 중요) | N | 긴급도에 따라 우선순위를 가려야 리소스 효율이 높습니다. |
| B | 1 → 3 → 2 (P0 → P1 → P2 순) | Y | 정답입니다! ChatGPT 비노출은 즉시 영향(KPI-A 낙폭), 경쟁사 Overviews는 조금 더 오래 걸릴 우려, "비교" 질문은 추가 콘텐츠 필요하므로 계획 수립 후 진행해야 합니다. |
| C | 2 → 1 → 3 (경쟁사 먼저) | N | 경쟁사 분석은 중요하지만, 자사 콘텐츠 개선(1, 3)이 먼저입니다. |
| D | 3 → 1 → 2 (기존 페이지 개선부터) | N | 1번처럼 전혀 새로운 이슈(비노출)가 더 긴급합니다. |

---

### **M6-7: 캡스톤 평가** (Capstone: Integration & Execution Capability)

**목표**: 90일 실행 계획 완성, 4주 리포트 작성, 개선 로그 정리, 우선순위 백로그 수립으로 실행 역량을 종합 평가

**커버 티켓**: P0-1~P2-11 (전체 59개 티켓), 90일 전체 로드맵 + 분기 리포트 + 개선 백로그

**커버 섹션**: §6 (Full Backlog), 90-day Roadmap visualization, §7 (Measurement summary)

#### 스텝 구성

**Step 7.1: Reading — "캡스톤: 90일 실행 계획과 4주 리포트 통합"** (순서: 1)

**목표**: 지난 6개 모듈에서 학습한 모든 요소를 "실제 작동하는 운영 시스템"으로 통합하고, 이를 문서화

**콘텐츠 구조**:
```
## 캡스톤: 90일 실행 계획과 4주 리포트 통합

### 1) Stage 6 학습 경로 회고

이제까지 배운 7개 모듈이 어떻게 연결되는가:

```
M6-1 (Governance)
  ↓ [Owner, KPI 베이스라인, 주간 리듬 확정]
  ├→ M6-2 (Page) [대상 페이지 10개 Answer-first/Proof]
  ├→ M6-3 (Schema) [기술 검증 파이프라인]
  ├→ M6-4 (Links) [Hub-Spoke 구조 설계]
  ├→ M6-5 (Off-site) [채널별 배포 캘린더]
  └→ M6-6 (Measurement) [Top 50 질문 주간 추적]
      ↓
  모든 모듈의 산출물
      ↓
  M6-7 (Capstone)
    - 90일 계획 통합 ✓
    - 4주 리포트 작성 ✓
    - 개선 로그 정리 ✓
    - 다음 분기 백로그 우선순위 ✓
```

### 2) 최종 제출 산출물 4개

#### (1) 90일 실행 계획 (Integrated Roadmap)

**구성**:
- Phase 1 (30일) 일정: P0-1~P0-28 (28개 티켓), 담당자, 승인자, 마감일
- Phase 2 (60일) 일정: P1-1~P1-20 (20개 티켓)
- Phase 3 (90일) 일정: P2-1~P2-11 (11개 티켓)
- 의존성: "P0-1 완료 후 P0-6 시작 가능" 같은 선행조건
- KPI 마일스톤: 30/60/90일의 KPI-A/B/C 목표

**템플릿 예시**:
```
[Stage 6 90일 실행 계획]

### Phase 1: 기반 정비 (30일) — Week 1~4

| 주차 | 티켓 | 액션아이템 | 담당 | 마감 | 승인자 | 의존성 |
|------|------|----------|------|------|--------|--------|
| W1 | P0-1~P0-5 | robots.txt, sitemap.xml, schema audit, ChatGPT tracking | 개발팀 | 2/28 | 마케팅 리드 | - |
| W1-2 | P0-26~P0-28 | Top 50 질문, 주간 로그 시트, 추적 루틴 | 마케팅 | 3/7 | Owner | P0-1~5 |
| W2-3 | P0-6~P0-15 | 상위 10 Answer-first (5인 리뷰) | 콘텐츠팀 | 3/14 | 마케팅 | P0-26 |
| W2-3 | P0-16~P0-25 | 상위 10 Proof-first (출처 검증) | 콘텐츠팀 | 3/14 | 마케팅 | P0-6~15 |

### Phase 2: 팬아웃 확장 (60일) — Week 5~8

| 주차 | 티켓 | 액션아이템 | 담당 | 마감 | 의존성 |
|------|------|----------|------|------|--------|
| W5-6 | P1-1~P1-7 | 허브 7개 구축 | 콘텐츠팀 | 4/18 | P0-1~28 |
| W5-8 | P1-8~P1-10 | 스포크 60개 (3 Batches) | 콘텐츠팀 | 5/2 | P1-1~7 |
| W6-8 | P1-11~P1-20 | 자산 표준화 + 내부링크 | 콘텐츠+개발팀 | 5/2 | P1-1~7 |

### Phase 3: 권위·자동화 (90일) — Week 9~13

| 주차 | 티켓 | 액션아이템 | 담당 | 마감 |
|------|------|----------|------|------|
| W9-10 | P2-1~P2-5 | 구조화 데이터 정착 | 개발팀 | 5/23 |
| W9-13 | P2-6~P2-11 | 내부링크 그래프 + 외부권위 + AI Validator 자동화 | 전팀 | 6/20 |

### KPI 마일스톤

| 기간 | KPI-A (ChatGPT 인용) | KPI-B (Google AI 노출) | KPI-C (하위질의 커버) |
|------|------------|-----------|-----------|
| 현재 | Baseline | Baseline | 35% |
| 30일 | +20% | Baseline 수립 | 55% |
| 60일 | +50% | +30% | 70% |
| 90일 | +150~200% | +80% | 85%+ |

### 의존성 매트릭스

```
P0-1 (robots) → P0-2 (sitemap) → P0-3 (schema audit)
P0-26 (Top 50) → P0-27 (log sheet) → P0-28 (routine)
P0-6~15 (Answer) + P0-26 → P0-16~25 (Proof)
P0-1~28 → P1-1~7 (Hubs)
P1-1~7 → P1-8~10 (Spokes)
P2-1~7 → P2-8~11 (External + Automation)
```

#### (2) 4주 성과 리포트 (Integrated Performance)

**구성**:
- 실행 현황 (예정 vs 실제)
- KPI 진도 (% 달성)
- 발견사항 3개 (좋았던 점 / 어려웠던 점 / 경쟁사 변화)
- 개선 액션 2~3개 (우선순위 순)

**템플릿 예시**:
```
[Stage 6 4주 성과 리포트]
기간: 2026-02-24 ~ 2026-03-23 (Week 09~12)

### 실행 현황

예정: 28개 P0 티켓 중 20개 (71%)
실제: 18개 (64%) — 지연 2개

지연 사유:
- P0-3 (Schema Audit): 현재 상태 분석 범위 확대로 3일 연장
- P0-16~25 (Proof-first): 출처 검증 프로세스 신설로 2일 소요

### KPI 진도

| KPI | 초기 | 4주 후 | 진도율 | 목표 대비 |
|-----|------|--------|--------|---------|
| KPI-A (ChatGPT) | 6 인용/주 | 8 인용/주 | +33% | 목표 +20% (초과 달성) ✓ |
| KPI-B (Google AI) | Baseline 미수립 | 기준 수립 (주 30 노출) | 100% | - |
| KPI-C (커버리지) | 32% | 36% | +4pp | 목표 +8pp (진행 중) |

### 발견사항

**좋았던 점 (Keep)**:
1. M6-1의 RACI 정렬로 인해 페이지 승인 대기 시간 ↓ (평균 5일 → 2일)
2. Answer-first 템플릿 채택으로 작성 속도 ↑ (시간/페이지: 8시간 → 4시간)
3. 주간 인용 로그로 낙폭 페이지를 즉시 탐지 가능해짐 (반응 시간: 3주 → 2일)

**어려웠던 점 (Fix)**:
1. Proof 블록 출처 검증이 예상보다 오래 걸림 (협력사 검증 지연)
   → 해결: 출처 템플릿 사전 준비 + 검증 권한 분산
2. Hub 7개 설계 중 IA 충돌 발생 (허브 3과 4의 중복)
   → 해결: IA 맵 재검토 + 허브 3 스포크를 4로 통합
3. 스키마 4단계 검증에 2배 시간 소요
   → 해결: 검증 자동화 스크립트 개발 계획 (P2 추가)

**경쟁사 변화 (Watch)**:
- 경쟁사 A: 새로운 "AI 교육 벤치마크" 리포트 발행 (Google Overviews 노출 상승)
  → 대응: 우리도 "기업 AI 교육 2026 트렌드" 리포트 우선 발행 (P1-8 앞당김)

### 개선 액션

**P0: 즉시 (5일 내)**:
- [ ] Proof 출처 템플릿 1차 버전 완성 (마케팅, 2/26)
- [ ] 스키마 검증 스크립트 개발 요청 (개발팀, 2/27)

**P1: 이번 주 (주 내)**:
- [ ] Hub 3/4 IA 통합 결정 + 영향도 분석 (콘텐츠, 3/3)
- [ ] "AI 교육 비용" 스포크 발행 계획 (마케팅, 3/3)

**P2: 다음 주 (내 주)**:
- [ ] 다음 월 오프사이트 배포 자산 확정
```

#### (3) 개선 로그 (What We Learned)

**구성**:
- 의사결정 사항 (RACI 변경, 우선순위 변경, 프로세스 신설)
- 트레이드오프 (효율 vs 품질 선택)
- 다음 분기 영향도

**템플릿 예시**:
```
[Stage 6 개선 로그]

### 1) RACI 변경

**변경**: Schema Validator (Google Rich Results Test)에서 발견된 오류는
개발팀(R) 단독이 아니라, 마케팅(A) 사전 검증 후 개발팀 반영으로 변경

**이유**: 페이지 유형 오남용(Contact→Course) 같은 구조적 오류는
마케팅이 먼저 탐지해야 개발팀 작업 재작업 방지

**효과**: 검증 반복 ↓ (스키마 재작업 0건 → 목표 유지)

### 2) 우선순위 변경

**Before**: P1-8~10 (Spoke 60개) → 균등 분배 (20/20/20)
**After**: P1-8 (Batch 1, 20개) → P1-9 (Batch 2, 20개) 순서 유지
          단, "AI 교육 비용" 스포크는 P0로 상향 (경쟁사 대응)

**이유**: KPI-C 커버리지에서 "비용" 관련 미노출 질문이 매주 상위 3개에 지속

**효과**: 경쟁사 대비 대응 속도 ↑

### 3) 프로세스 신설

**신설**: "Schema Validator → 오류 분류 → 복잡도별 티켓 분리"
- Type A (단순 필드 누락): 개발팀 1시간 내 수정
- Type B (IA 오류): 마케팅+개발팀 협업 (1일 소요)
- Type C (레거시 호환성): 별도 검토 미팅 (3일 소요)

**효과**: 예측 가능한 일정 관리

### 4) 트레이드오프 기록

**선택**: "Proof 블록 완성도" vs "발행 속도"

현재: Proof 블록 3단계 (통계, 인용, 출처) 모두 포함 (6시간/페이지)
대안: 통계 + 출처만 (4시간/페이지)

**결정**: 초기 품질 우선. 나중에 템플릿화로 자동화

**근거**: KPI-A (ChatGPT 인용)에서 Proof 완성도가 직접 영향
```

#### (4) 다음 분기 우선순위 백로그 (Q2 Roadmap)

**구성**:
- P0 항목 (할 수 있는 것)
- P1 항목 (할 수도 있는 것)
- P2 항목 (해야 할 것)

**템플릿 예시**:
```
[2026 Q2 (4월~6월) GEO 실행 백로그]

### Phase 3 마무리 (P2-1~11)

P0 (필수):
- [ ] P2-6: Hub-Spoke IA 재설계 맵 (시각화 + 링크 매핑)
- [ ] P2-9: 오리지널 리포트 1호 발행 (기업 AI 교육 2026)
- [ ] P2-12: AI Validator 루틴 10 프롬프트 자동화

P1 (권장):
- [ ] P2-1~5: Organization/Breadcrumb/FAQPage 스키마 전사 적용
- [ ] P2-10: 고객 공동 케이스 2건
- [ ] P2-7: Spoke 상호 링크 자동화 스크립트

P2 (미래):
- [ ] P2-11: API 기반 인용 추적 대시보드 (분기 말)

### 추가 전략 아이템 (Phase 4 후보)

경쟁사 분석 결과 우리가 캐버하지 못한 질문:
- [ ] "금융/제조/서비스 산업별 AI 교육 차이" (Hub 8 신규 여부 검토)
- [ ] "AI 교육 정책/규제 변화" (이슈 추적)

우리 사이트 기술 개선:
- [ ] Next.js 렌더링 최적화 (현재 22/25 CSR → 목표 5/25 이하)
- [ ] Core Web Vitals 개선 (LCP 3초 → 1.5초)

### 리스크 및 대응

| 리스크 | 확률 | 영향 | 대응 |
|--------|------|------|------|
| P2-9 리포트 발행 지연 | M | H | 마케팅 2명 전담 (현재 1명 → 2명) |
| 경쟁사 새 Hub 발행 | L | H | 경쟁사 모니터링 주 2회 (현재 월 1회) |
| 스키마 규제 변화 (Google) | L | M | Google Search Central 구독 강화 |
```

### 3) 평가 기준

**합격 기준**:
- [ ] 90일 계획: 최소 3개 phase, 담당/마감/의존성 명시
- [ ] 4주 리포트: 실행 진도 + KPI 수치 + 발견사항 3개 이상
- [ ] 개선 로그: 의사결정 변화 2개 이상 + 트레이드오프 기록
- [ ] 다음 분기 백로그: P0/P1/P2 분류 + 리스크 매트릭스

**탈락 기준**:
- 90일 계획이 Phase 없이 단순 티켓 나열만
- 4주 리포트가 "완료됨" 같은 일반 문장만 포함
- KPI 진도 수치 없음 (정성평가만 존재)
- 다음 분기 계획 없음
```

**Visual Components**:
- `.diagram-box`: 7개 모듈 연결도 (M6-1~M6-7 의존성)
- `.flow-chart`: 90일 계획 (3 Phase × 주차별)
- `.hierarchy-box`: 4주 리포트 KPI 진도표
- `.code-example`: 90일 계획 템플릿 (복붙 가능)
- `.callout`: "캡스톤은 학습 평가가 아니라 운영 시스템 평가입니다"

**Extension MD**:
- 90일 계획 상세 템플릿 (구글 시트)
- 4주 리포트 작성 예시 (실제 데이터)
- 개선 로그 템플릿 (의사결정 문서화 포맷)
- 다음 분기 백로그 상세 (20개 항목 예시)

---

**Step 7.2: Quiz — "90일 계획 우선순위 판정"** (순서: 2)

**문제**:
```
현재 2주차 종료 시점에서 다음과 같은 상황이 발생했습니다:

- P0-1~5 (Tech Infrastructure): 완료 ✓
- P0-6~15 (Answer-first): 50% 진행 중
- P0-26~28 (Measurement Setup): 완료 ✓

이 시점에서 가장 적절한 다음 액션은?
```

**선택지**:

| A | P0-6~15를 모두 기다린 후 P0-16~25(Proof) 시작 | N | P0-16~25는 P0-6~15의 완료를 기다려야 하지만, 일부가 완료되면 바로 Proof 작업을 시작해야 리드타임을 줄입니다. |
| B | 완료된 5개 Answer 페이지부터 바로 Proof-first 작업 시작 | Y | 정답입니다! 90일 계획의 병렬 실행 기법입니다. P0-6~15 진행 중에도 완료된 것부터 다음 단계로 넘기면 전체 일정을 앞당길 수 있습니다. |
| C | 다른 P0 티켓으로 리소스 전환 | N | 이미 정한 P0 순서를 바꾸면 일정이 더 꼬입니다. |
| D | P1 (Hub 구축)을 미리 시작 | N | P1은 P0-1~28 완료 후 시작해야 한다는 의존성이 있습니다. |

---

**Step 7.3: Practice — "리스크 대응 의사결정"** (순서: 3)

**시나리오**:
```
4주차: P0-16~25 (Proof-first) 진행 중 발견된 문제:
- 출처 검증이 예상 (5시간/페이지) 보다 오래 걸림 (8시간/페이지)
- 현재 10개 중 4개만 완료 (목표: 10개/주)
- 일정: 3월말 → 4월 5일 연장 예상

이 상황에서 가장 적절한 대응은?
```

**선택지**:

| A | 검증 기준을 완화하고 빠르게 진행 | N | 품질 저하는 다음 주 AI Validator 측정에서 바로 드러나므로 역효과가 큽니다. |
| B | "출처 검증 자동화" 임시 스크립트 개발 + 마케팅 2명 추가 투입 | Y | 정답입니다! 리드타임 연장은 인정하되(4월 5일로 공식화), 근본 원인(출처 검증 프로세스)을 개선하는 것이 90일 계획의 다음 phase에 영향을 줄이는 방법입니다. |
| C | P0-16~25를 생략하고 P1로 진행 | N | Proof-first는 KPI-A (ChatGPT 인용)에 직접 영향하므로 생략할 수 없습니다. |
| D | 외부 업체에 아웃소싱 | N | 출처 검증은 도메인 지식이 필요해 아웃소싱 효율이 낮습니다. 내부 역량 강화가 맞습니다. |

---

**Step 7.4: Practice — "다음 분기 백로그 우선순위"** (순서: 4)

**시나리오**:
```
90일 평가 결과:

KPI 달성도:
- KPI-A: +180% (목표 +150%) ✓ 초과
- KPI-B: +65% (목표 +80%) — 목표 미달
- KPI-C: 82% (목표 85%) — 거의 달성

다음 분기(Q2) 전략으로 가장 적절한 것은?
```

**선택지**:

| A | KPI-A를 더 강화해 200% 달성 목표 | N | KPI-A는 이미 초과 달성했으므로, 약한 영역(KPI-B)에 리소스를 집중해야 합니다. |
| B | KPI-B 개선에 집중 (Google AI Overviews 노출 강화) | Y | 정답입니다! Google AI는 "다양한 출처"를 선호하므로, Q2는 외부 권위(P2-9: 리포트, P2-10: 케이스) 강화로 Google의 다양성 신호를 높여야 합니다. |
| C | KPI-C를 85% 도달 (스포크 추가 발행) | N | KPI-C는 이미 82%로 충분히 진행 중이므로 우선순위가 낮습니다. |
| D | 새로운 KPI 추가 (예: 전환율) | N | 90일 계획의 KPI 3가지에 집중해야 합니다. 새로운 KPI는 분석 리소스를 분산시킵니다. |

---

## 3. 콘텐츠 설계 원칙

### 3.1 Reading Steps 구조 (SOP 포맷)

**원칙**: 실행팀이 즉시 따라할 수 있는 절차 중심

**구조**:
1. **개요** (1~2문단): 왜 이것을 해야 하는가 + 최종 산출물
2. **실행 순서** (번호 리스트): 5~10개 스텝, 각 스텝의 예상 소요 시간, 의존성
3. **체크리스트** (박스 표기): DoD (Definition of Done) 명시적 나열
4. **템플릿** (코드 블록 또는 extension_md): 복붙 가능한 형식 제공
5. **일반적 실수** (Callout): "❌ 하지 말 것" vs "✅ 해야 할 것"

**길이**: 400~800줄 (단일 Reading)

### 3.2 Quiz Steps 설계

**원칙**: "이 결정이 맞는가?"를 판단하는 훈련

**질문 유형**:
- **우선순위 판정**: "어떤 것을 먼저 해야 하나?"
- **판정 기준**: "이것이 완료 기준을 만족하나?"
- **트레이드오프**: "효율 vs 품질 중 어느 것을 선택할 것인가?"
- **실패 패턴**: "이 실수의 원인은 무엇인가?"

**피드백 구조**:
- 정답: "정답입니다! [이유] [다음 행동]" (50자 이상)
- 오답: "문제점: [왜 틀렸는가] [올바른 대안]" (40자 이상)

### 3.3 Practice Steps 설계

**원칙**: 실제 팀 상황을 시뮬레이션해 의사결정 훈련

**시나리오 유형**:
- **배치 순서**: 여러 일정 중 우선순위 설정
- **리스크 대응**: 예상치 못한 상황에서의 대응 선택
- **지표 해석**: 데이터를 보고 결론 도출
- **백로그 재조정**: KPI 결과에 따른 다음 주 계획 수립

**피드백 구조**:
- 정답: "정답입니다! [근거] [실제 효과]" (50자 이상)
- 오답: "이 선택의 문제점: [부작용] [더 좋은 대안]" (40자 이상)

### 3.4 Visual Components 매핑

**Per Module 권장**:

| 모듈 | 주요 Visual | 보조 Visual |
|------|-----------|-----------|
| M6-1 | .hierarchy-box (RACI) | .flow-chart (주간 리듬) |
| M6-2 | .browser-mockup (페이지 레이아웃) | .flow-chart (리모델링 순서) |
| M6-3 | .flow-chart (4단계 검증) | .code-example (QA 템플릿) |
| M6-4 | .diagram-box (Hub-Spoke 트리) | .hierarchy-box (링크 유형) |
| M6-5 | .code-example (UTM 규칙) | .compare-cards (채널별 배포) |
| M6-6 | .hierarchy-box (KPI 정의표) | .code-example (인용 로그) |
| M6-7 | .diagram-box (모듈 연결도) | .flow-chart (90일 계획) |

---

## 4. 모듈 의존성 & 순서

```
M6-1 (Governance)
  ├─ 必須: RACI, 주간 리듬, 기준 페이지 확정
  └─ Unlock: M6-2, M6-3, M6-4, M6-5, M6-6 모두 진행 가능
      │
      ├─→ M6-2 (Page Structure)
      │    └─ 완료: 상위 10 랜딩 Answer-first/Proof
      │
      ├─→ M6-3 (Schema)
      │    └─ 완료: 기술 검증 파이프라인 체계화
      │
      ├─→ M6-4 (Internal Links)
      │    └─ 의존: M6-2 기준 페이지 확정 후
      │    └─ 완료: Hub-Spoke 구조 설계
      │
      ├─→ M6-5 (Off-site)
      │    └─ 의존: M6-1 KPI 베이스라인 설정 후
      │    └─ 완료: 월간 배포 캘린더 설정
      │
      └─→ M6-6 (Measurement)
           └─ 의존: M6-1 Top 50 질문 + 로그 시트 설정 후
           └─ 완료: 주간 KPI 추적 루틴

                    ↓
           M6-7 (Capstone)
           └─ 의존: M6-1~M6-6 모두 완료 (또는 진행 중 4주차 이상)
           └─ 평가: 90일 계획 + 4주 리포트 + 개선 로그 + 다음 백로그
```

**병렬 실행 가능**: M6-2, M6-3, M6-4, M6-5는 M6-1 완료 후 동시 진행 가능
**단계적 진입**: M6-6는 M6-1 완료 후 즉시 시작하되, 데이터는 M6-2/3 진행 따라 축적

---

## 5. 스텝/옵션 수량 추정

### Per-Module Breakdown

| 모듈 | Steps | Options | Content Lines (approx) | 특징 |
|------|-------|---------|----------------------|------|
| M6-1 | 4 | 12 | 300 | RACI + 주간 리듬 + 킥오프 체크리스트 |
| M6-2 | 4 | 12 | 350 | 리모델링 SOP + 섹션 배치 + CTA 연결 |
| M6-3 | 4 | 12 | 320 | 4단계 검증 + 타입 오남용 + QA 로그 |
| M6-4 | 4 | 12 | 340 | Hub-Spoke 구조 + 앵커 텍스트 + 순환링크 |
| M6-5 | 4 | 12 | 380 | 월간 캘린더 + 채널 매칭 + UTM + 리포팅 |
| M6-6 | 4 | 12 | 360 | 주간 SOP + 커버리지 평가 + 이슈 우선순위 |
| M6-7 | 4 | 12 | 400 | 90일 계획 + 4주 리포트 + 개선 로그 + 백로그 |
| **합계** | **28** | **84** | **~2,440** | **기존과 동일 구조 유지** |

### 콘텐츠 라인 수 (Reading + Quiz + Practice 합계)

- **Reading**: 250~300줄 (SOP + 템플릿)
- **Quiz**: 50~80줄 (문제 + 4 옵션 × 50자 피드백)
- **Practice × 2**: 100~160줄 (2개 시나리오 × 4 옵션 피드백)
- **합계/모듈**: 400~540줄

---

## 6. 구현 체크리스트 (개발팀용)

### seed.py 구현 단계

1. **Module 정의** (7개):
   - module_id: 6-1 ~ 6-7
   - order_idx: 1 ~ 7
   - title, description 정확성

2. **Step 정의** (28개):
   - 4개 step per module
   - order_idx 혼동 없음 (1~4 반복)
   - step_type: "reading", "quiz", "practice"

3. **Option 정의** (84개):
   - Quiz: 4 options (1 correct, 3 incorrect)
   - Practice: 4 options (1 correct, 3 failure scenarios)
   - is_correct: 정확히 1개만 True
   - feedback: 40자 이상, 존댓말, "why" + "how"

4. **Visual Components**:
   - Markdown 본문에 HTML class 삽입
   - `.callout`, `.flow-chart`, `.code-example`, `.hierarchy-box`, `.diagram-box`, `.browser-mockup`, `.compare-cards`

5. **Extension MD**:
   - 일부 step에 부가 콘텐츠 제공
   - 템플릿, 예시, 링크 포함

6. **Test 통과**:
   - Stage 6 unlock: `require_stage_complete=5, min_score_pct=70`
   - Module count = 7, Step count = 28, Option count = 84
   - M6-7 quiz step ≥ 1개
   - Feedback length ≥ 40자
   - Feedback polite form (존댓말)

---

## 7. 작성 우선순위 (LLM/Developer 기준)

### 1차: 기초 틀
- [ ] M6-1 Reading + Quiz 완성 (가장 짧고 명확)
- [ ] M6-7 Reading 골격 (Overview 제공)

### 2차: 실행 SOP
- [ ] M6-2 Reading (페이지 리모델링 SOP)
- [ ] M6-3 Reading (스키마 검증 SOP)
- [ ] M6-4 Reading (IA 설계 SOP)

### 3차: 운영 루틴
- [ ] M6-5 Reading (오프사이트 배포)
- [ ] M6-6 Reading (측정 루프)

### 4차: Quiz + Practice (모든 모듈)
- [ ] 각 모듈별 Quiz 2개 (Decision + Criteria)
- [ ] 각 모듈별 Practice 2개 (Scenario + Adjustment)

### 5차: 검증 및 최종화
- [ ] 모든 피드백 40자 이상 + 존댓말 확인
- [ ] Visual component 태그 삽입 확인
- [ ] Extension MD 링크 유효성 확인
- [ ] Test 케이스 통과 확인

---

## 8. 참고: 기존 seed.py의 구현 형식 (M6-2 예시)

```python
# --- Module 6-2: 서비스 페이지 리모델링 과업 ---
m = add_module(6, "6-2: 서비스 페이지 리모델링 과업",
               "service_custom을 GEO 응답 친화 구조로 재설계하는 실행 절차를 학습합니다.", 2)

add_step(m, "reading", "service_custom 리모델링 상세 가이드", (
    "## service_custom 리모델링 상세 가이드\n\n"
    "[마크다운 콘텐츠 본문...]\n\n"
    "### 실행 순서\n"
    "[SOP 항목 1~5]"
), 1, extension_md=(
    "### 복붙용 템플릿\n\n"
    "[추가 템플릿 콘텐츠]"
))

s = add_step(m, "quiz", "리모델링 우선순위의 핵심", (
    "service_custom 개선에서 가장 먼저 적용해야 하는 요소는 무엇인가요?"
), 2)

add_option(s, "A", "페이지 전체 애니메이션 교체", 0,
           "시각 요소 개선은 보조적입니다. [...50자 이상...]", 1)
add_option(s, "B", "정의문 + Answer-first 요약 + FAQ의 정보 구조", 1,
           "정답입니다! GEO 실행 초반에는 [...]", 2)
# ... C, D 옵션 추가

s = add_step(m, "practice", "실습: 섹션 배치 순서 설계", (
    "다음 중 service_custom 상단 섹션 배치 순서로 가장 적절한 것은?"
), 3)

add_option(s, "A", "[섹션 배치 A]", 0, "[피드백]", 1)
add_option(s, "B", "[섹션 배치 B]", 1, "정답입니다! [...]", 2)
# ...
```

---

## 9. 최종 산출물 목록

### 문서
- ✅ `docs/77-stage6-curriculum-design.md` (이 문서)

### 구현 (개발팀)
- `apps/api/seed.py` - M6-1~M6-7 추가/수정
- `tests/test_phase2.py` - Stage 6 검증 케이스

### 참고 (유지보수)
- `docs/71-stage6-task-module-strategy.md` (변경 없음, 참고만)
- `docs/75-stage6-seed-content-preparation.md` (변경 없음, 참고만)
- `docs/90-log.md` (업데이트: Stage 6 설계 완료 기록)

---

**버전 히스토리**:
- v1.0 (2026-02-23): 초안 작성, 7개 모듈 × 4 스텝 × 3 옵션 = 28/84 구조 제안
